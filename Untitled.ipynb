{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing pre-requiste package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loadind data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>862</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>8844</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>15602</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>31357</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>11862</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genres     id  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...    862   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   8844   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...  15602   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...  31357   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]  11862   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                         title  \n",
       "0                    Toy Story  \n",
       "1                      Jumanji  \n",
       "2             Grumpier Old Men  \n",
       "3            Waiting to Exhale  \n",
       "4  Father of the Bride Part II  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./movies_metadata.csv',usecols=['id','title','overview','genres'],nrows=10000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres       0\n",
       "id           0\n",
       "overview    29\n",
       "title        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overview']=df['overview'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def pre_processing(text,index,columns):\n",
    "    if type(text) is not int:\n",
    "        string=\"\"\n",
    "        for words in text.split():\n",
    "            word = (\"\".join(e for e in words if e.isalnum()))\n",
    "            word = word.lower()\n",
    "            word = re.sub(\":\",'',word)\n",
    "            if not word in stop_words:\n",
    "                string+=word + \" \"\n",
    "        df[columns][index] = string        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:04, 2141.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for index,rows in tqdm(df.iterrows()):\n",
    "    pre_processing(rows['overview'],index,'overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content based Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie recommendation based on overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run cell: 0:00:00.401236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from datetime import datetime as dt\n",
    "\n",
    "s=dt.now()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "overview_bow = vectorizer.fit_transform(df['overview'])\n",
    "print(\"Time taken to run cell:\",dt.now() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['overview_bow.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(overview_bow, 'overview_bow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tried with pairwise i.e cosine distance but the result was not satisfactory instead of that used linear kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity  = linear_kernel(overview_bow,overview_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./similarity.npy',similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.load('./similarity.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indextitle = pd.Series(df.index, index=df['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indextitle.to_csv('./indextitle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(title):\n",
    "    \n",
    "    id = indextitle[title]    \n",
    "    \n",
    "    similarity_score = list(enumerate(similarity[id]))\n",
    "#     print(similarity_score)\n",
    "    \n",
    "    #pair_distance = pairwise_distances(overview_bow,overview_bow[id])\n",
    "    indices = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    indices = indices[1:10]\n",
    "    \n",
    "    movie_indices = [i[0] for i in indices]\n",
    "#     print(movie_indices)\n",
    "    df_indices = list(df.index[movie_indices])\n",
    "    print(\"Similar movie of {} are: \\n\".format(df[\"title\"].loc[id]))\n",
    "    for i in range(0,len(indices)):\n",
    "        \n",
    "        print(\"{}\".format(df['title'].loc[df_indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Assassins are: \n",
      "\n",
      "The Blue Angel\n",
      "Possible Loves\n",
      "The Killer\n",
      "Heist\n",
      "Fulltime Killer\n",
      "The Watcher\n",
      "Dr. T and the Women\n",
      "30 YEARS TO LIFE\n",
      "Blame It on the Bellboy\n"
     ]
    }
   ],
   "source": [
    "bag_of_words('Assassins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Toy Story are: \n",
      "\n",
      "Toy Story 2\n",
      "Rebel Without a Cause\n",
      "Condorman\n",
      "Window to Paris\n",
      "Finian's Rainbow\n",
      "Malice\n",
      "Carried Away\n",
      "Dirty Work\n",
      "Vagabond\n"
     ]
    }
   ],
   "source": [
    "bag_of_words('Toy Story')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (10000, 36983)\n",
      "Time taken to run cell: 0:00:00.328831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import datetime as dt\n",
    "\n",
    "s=dt.now()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "overview_tfidf = vectorizer.fit_transform(df['overview'])\n",
    "print(\"Shape\",overview_tfidf.shape)\n",
    "\n",
    "print(\"Time taken to run cell:\",dt.now() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_tfidf  = linear_kernel(overview_tfidf,overview_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_based_recommendation(title):\n",
    "    \n",
    "    id = indextitle[title]    \n",
    "    \n",
    "    similarity_score = list(enumerate(similarity_tfidf[id]))\n",
    "    \n",
    "    #pair_distance = pairwise_distances(overview_bow,overview_bow[id])\n",
    "    indices = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    indices = indices[1:10]\n",
    "    \n",
    "    movie_indices = [i[0] for i in indices]\n",
    "#     print(movie_indices)\n",
    "    df_indices = list(df.index[movie_indices])\n",
    "    print(\"Similar movie of {} are: \\n\".format(df[\"title\"].loc[id]))\n",
    "    for i in range(0,len(indices)):\n",
    "        \n",
    "        print(\"{}\".format(df['title'].loc[df_indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Assassins are: \n",
      "\n",
      "The Blue Angel\n",
      "Branded to Kill\n",
      "Fulltime Killer\n",
      "The Quickie\n",
      "King of the Ants\n",
      "Dead or Alive 2: Birds\n",
      "The Killer\n",
      "The Fire Within\n",
      "Crane World\n"
     ]
    }
   ],
   "source": [
    "tfidf_based_recommendation('Assassins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Text Semantic based similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Building our own word2vec model since google glove vector consits of lots of data that is not useful.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 71249.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "overview_list = []\n",
    "\n",
    "for sent in tqdm(df['overview']):\n",
    "    overview_list.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9263\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "w2vmodel=Word2Vec(overview_list,min_count=5,size=50,workers=4)\n",
    "w2v_words = list(w2vmodel.wv.vocab)\n",
    "print(len(w2v_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:34<00:00, 46.67it/s]\n"
     ]
    }
   ],
   "source": [
    "overview_vector=[]\n",
    "for sent in tqdm(df['overview']):\n",
    "    sent_vec=np.zeros(50)\n",
    "    count=0\n",
    "    for word in sent:\n",
    "        if word in w2v_words:\n",
    "            vec = w2vmodel.wv[word]\n",
    "            sent_vec+=vec\n",
    "            count+=1\n",
    "    if count !=0:\n",
    "        sent_vec/=count\n",
    "    overview_vector.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_w2vec  = linear_kernel(overview_vector,overview_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_based_recommendation(title):\n",
    "    \n",
    "    id = indextitle[title]    \n",
    "#     print(id)\n",
    "    \n",
    "    similarity_score = list(enumerate(similarity_w2vec[id]))\n",
    "    \n",
    "    #pair_distance = pairwise_distances(overview_bow,overview_bow[id])\n",
    "    indices = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    indices = indices[1:10]\n",
    "    \n",
    "    movie_indices = [i[0] for i in indices]\n",
    "#     print(movie_indices)\n",
    "    df_indices = list(df.index[movie_indices])\n",
    "    print(\"Similar movie of {} are: \\n\".format(df[\"title\"].loc[id]))\n",
    "    for i in range(0,len(indices)):\n",
    "        \n",
    "        print(\"{}\".format(df['title'].loc[df_indices[i]]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Toy Story are: \n",
      "\n",
      "Oldboy\n",
      "The Last Castle\n",
      "Gentleman's Agreement\n",
      "After Life\n",
      "Marvin's Room\n",
      "Mr. Magoo\n",
      "Sodom and Gomorrah\n",
      "The Spanish Prisoner\n",
      "Uprising\n"
     ]
    }
   ],
   "source": [
    "w2v_based_recommendation('Toy Story')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we can see the result are ok but it need more improvement as compared to tfidf which is giving good result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie recommendation based on Movie Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from datetime import datetime as dt\n",
    "\n",
    "s=dt.now()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "title_bow = vectorizer.fit_transform(df['title'])\n",
    "print(\"Time taken to run cell:\",dt.now() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity  = linear_kernel(title_bow,title_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "indextitle = pd.Series(df.index, index=df['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(title):\n",
    "    \n",
    "    id = indextitle[title]    \n",
    "    \n",
    "    similarity_score = list(enumerate(similarity[id]))\n",
    "    \n",
    "    #pair_distance = pairwise_distances(overview_bow,overview_bow[id])\n",
    "    indices = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    indices = indices[1:10]\n",
    "    \n",
    "    movie_indices = [i[0] for i in indices]\n",
    "#     print(movie_indices)\n",
    "    df_indices = list(df.index[movie_indices])\n",
    "    print(\"Similar movie of {} are: \\n\".format(df[\"title\"].loc[id]))\n",
    "    for i in range(0,len(indices)):\n",
    "        \n",
    "        print(\"{}\".format(df['title'].loc[df_indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Toy Story are: \n",
      "\n",
      "Toy Story 2\n",
      "The Neverending Story III: Escape from Fantasia\n",
      "A Pyromaniac's Love Story\n",
      "The Story of Xinghua\n",
      "Police Story 3: Supercop\n",
      "The Philadelphia Story\n",
      "Entertaining Angels - The Dorothy Day Story\n",
      "The Line King: The Al Hirschfeld Story\n",
      "My Left Foot: The Story of Christy Brown\n"
     ]
    }
   ],
   "source": [
    "bag_of_words('Toy Story')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (10000, 7746)\n",
      "Time taken to run cell: 0:00:00.559081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import datetime as dt\n",
    "\n",
    "s=dt.now()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "title_tfidf = vectorizer.fit_transform(df['title'])\n",
    "print(\"Shape\",title_tfidf.shape)\n",
    "\n",
    "similarity_tfidf  = linear_kernel(title_tfidf,title_tfidf)\n",
    "print(\"Time taken to run cell:\",dt.now() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_based_recommendation(title):\n",
    "    \n",
    "    id = indextitle[title]    \n",
    "    \n",
    "    similarity_score = list(enumerate(similarity_tfidf[id]))\n",
    "    \n",
    "    #pair_distance = pairwise_distances(overview_bow,overview_bow[id])\n",
    "    indices = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    indices = indices[1:10]\n",
    "    \n",
    "    movie_indices = [i[0] for i in indices]\n",
    "#     print(movie_indices)\n",
    "    df_indices = list(df.index[movie_indices])\n",
    "    print(\"Similar movie of {} are: \\n\".format(df[\"title\"].loc[id]))\n",
    "    for i in range(0,len(indices)):\n",
    "        \n",
    "        print(\"{}\".format(df['title'].loc[df_indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Assassins are: \n",
      "\n",
      "Our Lady of the Assassins\n",
      "Toy Story\n",
      "Jumanji\n",
      "Grumpier Old Men\n",
      "Waiting to Exhale\n",
      "Father of the Bride Part II\n",
      "Heat\n",
      "Sabrina\n",
      "Tom and Huck\n"
     ]
    }
   ],
   "source": [
    "tfidf_based_recommendation('Assassins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendation based on Movie overview + title + genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('credits.csv',nrows=10000)\n",
    "keywords = pd.read_csv('keywords.csv',nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "df['id'] = df['id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(credits, on='id')\n",
    "df = df.merge(keywords, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =df.copy()\n",
    "final['cast'] = final['cast'].apply(literal_eval)\n",
    "final['crew'] = final['crew'].apply(literal_eval)\n",
    "final['keywords'] = final['keywords'].apply(literal_eval)\n",
    "final['cast_size'] = final['cast'].apply(lambda x: len(x))\n",
    "final['crew_size'] = final['crew'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['keywords'] = final['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = final.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      jealousy\n",
       "0           toy\n",
       "0           boy\n",
       "0    friendship\n",
       "0       friends\n",
       "Name: keyword, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in s:\n",
    "            words.append(i)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['keywords'] = final['keywords'].apply(filter_keywords)\n",
    "final['keywords'] = final['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "final['keywords'] = final['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['genres'] = final['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2str(final):\n",
    "    fin=[]\n",
    "    for i in final['genres']:\n",
    "        string=[]\n",
    "        for j in i:\n",
    "            string.append(j)\n",
    "        str1=\" \".join(string)\n",
    "        fin.append(str1)\n",
    "        \n",
    "    return fin    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['cl_genres']=list2str(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Animation Comedy Family\n",
       "1    Adventure Fantasy Family\n",
       "2              Romance Comedy\n",
       "3        Comedy Drama Romance\n",
       "4                      Comedy\n",
       "Name: cl_genres, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['cl_genres'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['soup'] = final['overview'] + final['title']  + final['cl_genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    led woody andys toys live happily room andys b...\n",
       "1    siblings judy peter discover enchanted board g...\n",
       "2    family wedding reignites ancient feud nextdoor...\n",
       "3    cheated mistreated stepped women holding breat...\n",
       "4    george banks recovered daughters wedding recei...\n",
       "Name: soup, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['soup'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(final['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "indextitle = pd.Series(final.index, index=final['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    \n",
    "    id = indextitle[title]    \n",
    "    \n",
    "    similarity_score = list(enumerate(cosine_sim[id]))\n",
    "    \n",
    "    #pair_distance = pairwise_distances(overview_bow,overview_bow[id])\n",
    "    indices = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    indices = indices[1:10]\n",
    "    \n",
    "    movie_indices = [i[0] for i in indices]\n",
    "#     print(movie_indices)\n",
    "    df_indices = list(df.index[movie_indices])\n",
    "    print(\"Similar movie of {} are: \\n\".format(df[\"title\"].loc[id]))\n",
    "    for i in range(0,len(indices)):\n",
    "        \n",
    "        print(\"{}\".format(df['title'].loc[df_indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Assassins are: \n",
      "\n",
      "Fulltime Killer\n",
      "King of the Ants\n",
      "Thunderheart\n",
      "The 1,000 Eyes of Dr. Mabuse\n",
      "The Blue Angel\n",
      "The Killer\n",
      "I Hired a Contract Killer\n",
      "Never Die Alone\n",
      "Cellular\n"
     ]
    }
   ],
   "source": [
    "get_recommendations('Assassins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "count = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix_tfidf = count.fit_transform(final['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_tfidf = cosine_similarity(count_matrix_tfidf, count_matrix_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    \n",
    "    id = indextitle[title]   \n",
    "    \n",
    "    similarity_score = list(enumerate(cosine_sim_tfidf[id]))\n",
    "    \n",
    "    #pair_distance = pairwise_distances(overview_bow,overview_bow[id])\n",
    "    indices = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    indices = indices[1:10]\n",
    "    \n",
    "    movie_indices = [i[0] for i in indices]\n",
    "#     print(movie_indices)\n",
    "    df_indices = list(df.index[movie_indices])\n",
    "    print(\"Similar movie of {} are: \\n\".format(df[\"title\"].loc[id]))\n",
    "    for i in range(0,len(indices)):\n",
    "        \n",
    "        print(\"{}\".format(df['title'].loc[df_indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Assassins are: \n",
      "\n",
      "The Blue Angel\n",
      "King of the Ants\n",
      "The Shooting\n",
      "The Killer\n",
      "I Hired a Contract Killer\n",
      "Beyond Hypothermia\n",
      "The Quickie\n",
      "Fulltime Killer\n",
      "The Eiger Sanction\n"
     ]
    }
   ],
   "source": [
    "get_recommendations('Assassins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Task 1 : Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ajay/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10018/10018 [00:09<00:00, 1074.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "text_data = []\n",
    "\n",
    "for line in tqdm(final['overview']):\n",
    "    tokens = prepare_text_for_lda(line)\n",
    "    text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "# import pickle\n",
    "# pickle.dump(corpus, open(path + 'corpus.pkl', 'wb'))\n",
    "# dictionary.save(path + '/dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:39.490024\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from datetime import datetime\n",
    "\n",
    "s = datetime.now()\n",
    "\n",
    "NUM_TOPICS = 20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "# ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=10)\n",
    "print(datetime.now() - s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df = pd.DataFrame()\n",
    "\n",
    "# Get main topic in each document\n",
    "for i, row in enumerate(ldamodel[corpus]):\n",
    "#     row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "    # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "    for j, (topic_num, prop_topic) in enumerate(row):\n",
    "        if j == 0:  # => dominant topic\n",
    "            wp = ldamodel.show_topic(topic_num)\n",
    "            topic_keywords = \", \".join([word for word, prop in wp])\n",
    "            sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "        else:\n",
    "            break\n",
    "sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "# Add original text to the end of the output\n",
    "contents = pd.Series(text_data)\n",
    "sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "df_topic_sents_keywords = sent_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>feature</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>young, woman, family, child, discover, father,...</td>\n",
       "      <td>[woody, andys, happily, andys, birthday, bring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>alien, documentary, revenge, violent, creature...</td>\n",
       "      <td>[sibling, peter, discover, enchant, board, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5593</td>\n",
       "      <td>tommy, francisco, avenge, route, stranger, alo...</td>\n",
       "      <td>[family, wedding, reignite, ancient, nextdoor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>young, woman, family, child, discover, father,...</td>\n",
       "      <td>[cheat, mistreat, step, woman, holding, breath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>young, woman, family, child, discover, father,...</td>\n",
       "      <td>[george, banks, recover, daughter, wedding, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>movie, story, mystery, director, base, star, f...</td>\n",
       "      <td>[obsessive, master, thief, mccauley, lead, top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3225</td>\n",
       "      <td>young, woman, family, child, discover, father,...</td>\n",
       "      <td>[duckling, undergo, remarkable, change, still,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>young, woman, family, child, discover, father,...</td>\n",
       "      <td>[mischievous, young, sawyer, witness, murder, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>alien, documentary, revenge, violent, creature...</td>\n",
       "      <td>[international, action, superstar, claude, dam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>skill, governor, boxing, widower, indian, pris...</td>\n",
       "      <td>[james, unmask, mysterious, janus, syndicate, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             2.0              0.2529   \n",
       "1            1             0.0              0.0505   \n",
       "2            2             7.0              0.5593   \n",
       "3            3             2.0              0.8972   \n",
       "4            4             2.0              0.3562   \n",
       "5            5             3.0              0.6106   \n",
       "6            6             2.0              0.3225   \n",
       "7            7             2.0              0.2297   \n",
       "8            8             0.0              0.1058   \n",
       "9            9            10.0              0.1587   \n",
       "\n",
       "                                             feature  \\\n",
       "0  young, woman, family, child, discover, father,...   \n",
       "1  alien, documentary, revenge, violent, creature...   \n",
       "2  tommy, francisco, avenge, route, stranger, alo...   \n",
       "3  young, woman, family, child, discover, father,...   \n",
       "4  young, woman, family, child, discover, father,...   \n",
       "5  movie, story, mystery, director, base, star, f...   \n",
       "6  young, woman, family, child, discover, father,...   \n",
       "7  young, woman, family, child, discover, father,...   \n",
       "8  alien, documentary, revenge, violent, creature...   \n",
       "9  skill, governor, boxing, widower, indian, pris...   \n",
       "\n",
       "                                                Text  \n",
       "0  [woody, andys, happily, andys, birthday, bring...  \n",
       "1  [sibling, peter, discover, enchant, board, ope...  \n",
       "2  [family, wedding, reignite, ancient, nextdoor,...  \n",
       "3  [cheat, mistreat, step, woman, holding, breath...  \n",
       "4  [george, banks, recover, daughter, wedding, re...  \n",
       "5  [obsessive, master, thief, mccauley, lead, top...  \n",
       "6  [duckling, undergo, remarkable, change, still,...  \n",
       "7  [mischievous, young, sawyer, witness, murder, ...  \n",
       "8  [international, action, superstar, claude, dam...  \n",
       "9  [james, unmask, mysterious, janus, syndicate, ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'feature', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_keywords = df_dominant_topic.drop(['Document_No','Dominant_Topic','Topic_Perc_Contrib','Text'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([final, topic_keywords],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>title</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cast_size</th>\n",
       "      <th>crew_size</th>\n",
       "      <th>cl_genres</th>\n",
       "      <th>soup</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>862</td>\n",
       "      <td>led woody andys toys live happily room andys b...</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>Animation Comedy Family</td>\n",
       "      <td>led woody andys toys live happily room andys b...</td>\n",
       "      <td>young, woman, family, child, discover, father,...</td>\n",
       "      <td>young, woman, family, child, discover, father,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>8844</td>\n",
       "      <td>siblings judy peter discover enchanted board g...</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>[]</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>Adventure Fantasy Family</td>\n",
       "      <td>siblings judy peter discover enchanted board g...</td>\n",
       "      <td>alien, documentary, revenge, violent, creature...</td>\n",
       "      <td>alien, documentary, revenge, violent, creature...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         genres    id  \\\n",
       "0   [Animation, Comedy, Family]   862   \n",
       "1  [Adventure, Fantasy, Family]  8844   \n",
       "\n",
       "                                            overview      title  \\\n",
       "0  led woody andys toys live happily room andys b...  Toy Story   \n",
       "1  siblings judy peter discover enchanted board g...    Jumanji   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "\n",
       "                                                crew keywords  cast_size  \\\n",
       "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...       []         13   \n",
       "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...       []         26   \n",
       "\n",
       "   crew_size                 cl_genres  \\\n",
       "0        106   Animation Comedy Family   \n",
       "1         16  Adventure Fantasy Family   \n",
       "\n",
       "                                                soup  \\\n",
       "0  led woody andys toys live happily room andys b...   \n",
       "1  siblings judy peter discover enchanted board g...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  young, woman, family, child, discover, father,...   \n",
       "1  alien, documentary, revenge, violent, creature...   \n",
       "\n",
       "                                             feature  \n",
       "0  young, woman, family, child, discover, father,...  \n",
       "1  alien, documentary, revenge, violent, creature...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for topic in topics:\n",
    "#     print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10018/10018 [00:06<00:00, 1530.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_vecs2 = []\n",
    "for i in tqdm(range(len(text_data))):\n",
    "    top_topics = ldamodel.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(20)]\n",
    "    topic_vec.extend([len(final.iloc[i].overview)]) # length review\n",
    "    train_vecs2.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim_topic_modeling = cosine_similarity(train_vecs2, train_vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_topic(title):\n",
    "    \n",
    "    id = indextitle[title]   \n",
    "    \n",
    "    similarity_score = list(enumerate(cosine_sim_topic_modeling[id]))\n",
    "    \n",
    "    #pair_distance = pairwise_distances(overview_bow,overview_bow[id])\n",
    "    indices = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    indices = indices[1:10]\n",
    "    \n",
    "    movie_indices = [i[0] for i in indices]\n",
    "#     print(movie_indices)\n",
    "    df_indices = list(df.index[movie_indices])\n",
    "    print(\"Similar movie of {} are: \\n\".format(df[\"title\"].loc[id]))\n",
    "    for i in range(0,len(indices)):\n",
    "        \n",
    "        print(\"{}\".format(df['title'].loc[df_indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Toy Story are: \n",
      "\n",
      "The Amati Girls\n",
      "The Château\n",
      "Lovely & Amazing\n",
      "Somebody Is Waiting\n",
      "The House of Mirth\n",
      "Envy\n",
      "Sunshine\n",
      "Desperate Hours\n",
      "The Royal Tenenbaums\n"
     ]
    }
   ],
   "source": [
    "get_recommendations_topic('Toy Story')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using topic modeling together with title + overview + genre and lets see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_with_topic = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_with_topic['feature'] = final['soup'] + final['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(final_with_topic['feature'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim_topic_modeling = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar movie of Toy Story are: \n",
      "\n",
      "The Amati Girls\n",
      "The Château\n",
      "Lovely & Amazing\n",
      "Somebody Is Waiting\n",
      "The House of Mirth\n",
      "Envy\n",
      "Sunshine\n",
      "Desperate Hours\n",
      "The Royal Tenenbaums\n"
     ]
    }
   ],
   "source": [
    "get_recommendations_topic('Toy Story')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
